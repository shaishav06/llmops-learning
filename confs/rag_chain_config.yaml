guardrail_config:
  model: anthropic.claude-3-haiku-20240307-v1:0
  topics:
    valid:
      - HR Policies
      - company culture
      - team building
      - leadership
      - management
      - productivity
      
    invalid:
      - software programming
      - religion
      - politics
      - sports
input_example:
  messages:
  - content: What is the company's sick leave policy?
    role: user
  - content: The company's sick leave policy allows employees to take a certain number
      of sick days per year. Please refer to the employee handbook for specific details
      and eligibility criteria.
    role: assistant
  - content: How many sick days can I take per year?
    role: user
output_example:
  result: "example text"
  sources:
    - "example_source_1.pdf"
    - "example_source_2.pdf"
  
llm_config:
  llm_model: anthropic.claude-3-haiku-20240307-v1:0
  llm_parameters:
    max_tokens: 4000
    temperature: 0.01
  llm_prompt_template: "\n                You are a trustful assistant for HR Policies.\
    \ You are answering employee benefits, leave policies, performance management,\
    \ recruitment, onboarding, and other HR-related topics. If you do not know the\
    \ answer to a question, you truthfully say you do not know. Read the discussion\
    \ to get the context of the previous conversation. In the chat discussion, you\
    \ are referred to as \"system\". The user is referred to as \"user\".\n\n    \
    \            Discussion: {chat_history}\n\n                Here's some context\
    \ which might or might not help you answer: {context}\n\n                Answer\
    \ straight, do not repeat the question, do not start with something like: the\
    \ answer to the question, do not add \"AI\" in front of your answer, do not say:\
    \ here is the answer, do not mention the context or the question.\n\n        \
    \        Based on this history and context, answer this question: {question}\n\
    \                "
  llm_refusal_fallback_answer: I cannot answer this question.
  query_rewriter_prompt_template: "\n                Based on the chat history below,\
    \ we want you to generate a query for an external data source to retrieve relevant\
    \ documents so that we can better answer the question. The query should be in\
    \ natual language. The external data source uses similarity search to search for\
    \ relevant documents in a vector space. So the query should be similar to the\
    \ relevant documents semantically. Answer with only the query. Do not add explanation.\n\
    \n                Chat history: {chat_history}\n\n                Question: {question}\n\
    \                "
retriever_config:
  embedding_model: "amazon.titan-embed-text-v1"
  parameters:
    k: 10
    score_threshold: 0.5
  schema:
    document_uri: source
  vector_store_path: "http://localhost:6333"
  collection_name: "hr-documents"
